{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d83357",
   "metadata": {},
   "source": [
    "# Finite mixture models\n",
    "\n",
    "## Principle\n",
    "\n",
    "The energy signature models only offer a coarse disaggregation of energy use into three components: heating, cooling, and baseline consumption. Furthermore, they rely on very long sampling times and cannot predict sub-daily consumption profiles. Finite Mixture Models (FMM) are one way to take the disaggregation of the baseline energy consumption further. Their most common specific case are the Gaussian Mixture Models (GMM).\n",
    "\n",
    "Finite mixture models assume that the outcome $y$ is drawn from one of several distributions, the identity of which is controlled by a categorical mixing distribution.\\cite{stan_guide} For instance, the mixture of $K$ normal distributions $f$ with locations $\\mu_k$ and scales $\\sigma_k$ reads:\n",
    "\\begin{equation}\n",
    "\tp(y_i|\\lambda, \\mu, \\sigma) = \\sum_{k=1}^K \\lambda_k f(y_i|\\mu_k,\\sigma_k)\n",
    "\t(\\#eq:fmm)\n",
    "\\end{equation}\n",
    "where $\\lambda_k$ is the (positive) mixing proportion of the $k$th component and $\\sum_{k=1}^K \\lambda_k = 1$. The FMM distributes the observed values into a finite number of distributions with probability $\\lambda_k$. The optimal number of components is not always a trivial choice: studies involving GMM often rely on some model selection index, such as the Bayesian Information Criterion (BIC), to guide the choice of the appropriate value for $K$. \n",
    "\n",
    "The dependency of observations $y$ on explanatory variables $x$ can be included in the FMM, by formulating its parameters $\\left\\{ \\lambda_k(x), \\mu_k(x), \\sigma_k(x) \\right\\}$ as dependent on the given value $x$ of these regressors. Furthermore, in order to include the effects of different power consumption demand behaviours, the mixture probabilities $\\lambda_k$ can be modelled as dependent on a categorical variable $z$. Finite Mixture Models thus offer a very high flexibility for attempting to disaggregate and predict energy uses, while including the possible effects of continuous or discrete explanatory variables.\n",
    "\n",
    "## Example\n",
    "\n",
    "This example uses a data file provided [in the book's repository](https://github.com/srouchier/buildingenergygeeks/tree/master/data). The tutorial below is written in **R** and uses [Stan](https://mc-stan.org/). Unsurprisingly, the Stan user's guide also has [a chapter on finite mixtures](https://mc-stan.org/docs/2_27/stan-users-guide/mixture-modeling-chapter.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4bc8bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "Loading required package: StanHeaders\n",
      "rstan (Version 2.17.3, GitRev: 2e1f913d3ca3)\n",
      "For execution on a local, multicore CPU with excess RAM we recommend calling\n",
      "options(mc.cores = parallel::detectCores()).\n",
      "To avoid recompilation of unchanged Stan programs, we recommend calling\n",
      "rstan_options(auto_write = TRUE)\n",
      "── Attaching packages ─────────────────────────────────────── tidyverse 1.2.1 ──\n",
      "✔ tibble  1.4.2     ✔ purrr   0.2.5\n",
      "✔ tidyr   0.8.1     ✔ dplyr   0.7.6\n",
      "✔ readr   1.1.1     ✔ stringr 1.2.0\n",
      "✔ tibble  1.4.2     ✔ forcats 0.3.0\n",
      "── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "✖ tidyr::extract() masks rstan::extract()\n",
      "✖ dplyr::filter()  masks stats::filter()\n",
      "✖ dplyr::lag()     masks stats::lag()\n",
      "Parsed with column specification:\n",
      "cols(\n",
      "  mean_consumption = col_double(),\n",
      "  ratio_house = col_double(),\n",
      "  ratio_apartment = col_double()\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       " mean_consumption  ratio_house     ratio_apartment \n",
       " Min.   : 0.770   Min.   :0.0000   Min.   :0.0000  \n",
       " 1st Qu.: 3.753   1st Qu.:0.2006   1st Qu.:0.1181  \n",
       " Median : 5.146   Median :0.6346   Median :0.3654  \n",
       " Mean   : 5.499   Mean   :0.5523   Mean   :0.4477  \n",
       " 3rd Qu.: 6.939   3rd Qu.:0.8819   3rd Qu.:0.7994  \n",
       " Max.   :41.805   Max.   :1.0000   Max.   :1.0000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "20744"
      ],
      "text/latex": [
       "20744"
      ],
      "text/markdown": [
       "20744"
      ],
      "text/plain": [
       "[1] 20744"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "library(rstan)\n",
    "library(tidyverse)\n",
    "\n",
    "df <- read_csv(\"data/mixture.csv\")\n",
    "summary(df)\n",
    "nrow(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1878ed4d",
   "metadata": {},
   "source": [
    "This data file is an excerpt of an energy consumption census in France. Each row represents an \"area\" of about 2,000 residents. The available data are the mean residential energy consumption in each area, and the ratios of houses and apartments.\n",
    "\n",
    "On average, we expect a house to have a higher energy consumption than an apartment: it is larger, has more residents, and more envelope surface with heat loss. Therefore, we can expect areas with more houses to have a higher mean consumption than areas with more apartments.\n",
    "\n",
    "Let us look at a pairplot of the three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f218c15f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in library(GGally): there is no package called ‘GGally’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(GGally): there is no package called ‘GGally’\nTraceback:\n",
      "1. library(GGally)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "library(GGally)\n",
    "ggpairs(df, columns=c(\"mean_consumption\", \"ratio_house\", \"ratio_apartment\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe3a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "There is indeed *some* correlation between the ratio of houses in each area and the mean consumption. The density of `ratio_house` is strongly bimodal, and the density of `mean_consumption` looks like it could be split into two distributions as well.\n",
    "\n",
    "We can now try to translate our assumptions into a simple mixture of two distributions. Equation \\@ref(eq:hmm) can be formulated as such:\n",
    "\\begin{equation}\n",
    "p(y_t | \\lambda, \\mu, \\sigma) = \\lambda_t f\\left(y_t | \\mu_1, \\sigma_1 \\right) + (1-\\lambda_t) f\\left(y_t | \\mu_2, \\sigma_2 \\right) (\\#eq:fmm2)\n",
    "\\end{equation}\n",
    "where, for each data point $t$,\n",
    "\n",
    "* $y_t$ is the dependent variable `mean_consumption`.\n",
    "* $\\lambda_t$ is the explanatory variable `ratio_house`.\n",
    "* $f$ is a type of continuous probability distribution. It can be Normal, Gamma, LogNormal, etc.\n",
    "* $\\mu$ and $\\sigma$ are the parameters of the distribution $f$ that we will choose. The indices $1$ and $2$ denote each of the two mixture components.\n",
    "\n",
    "This is a Stan mixture model with any number `K` of components:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0139f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture <- \"\n",
    "data {\n",
    "  // This block declares all data which will be passed to the Stan model.\n",
    "  int<lower=0> N;       // number of data items in the training dataset\n",
    "  int<lower=0> K;       // number of components\n",
    "  real y[N];            // outcome energy vector\n",
    "  real l[N, K];         // ratios in the training dataset\n",
    "}\n",
    "parameters {\n",
    "  // This block declares the parameters of the model.\n",
    "  vector[K] mu;\n",
    "  vector[K] sigma;\n",
    "}\n",
    "model {\n",
    "  for (n in 1:N) {\n",
    "    vector[K] lps;\n",
    "    for (k in 1:K) {\n",
    "      lps[k] = log(l[n, k]) + lognormal_lpdf(y[n] | mu[k], sigma[k]);\n",
    "    }\n",
    "    target += log_sum_exp(lps);\n",
    "  }\n",
    "}\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1390971d",
   "metadata": {},
   "source": [
    "We can separate the data into a training set and a test set like so. The following block allocates 75% of the data to the training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe74856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set.seed(12345)  # this is optional but ensures that results are reproducible\n",
    "train_ind <- sample(seq_len(nrow(df)), size = floor(0.75 * nrow(df)))\n",
    "\n",
    "train <- df[train_ind, ]\n",
    "test <- df[-train_ind, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb5c78f",
   "metadata": {},
   "source": [
    "The next step maps the data to the Stan model and runs the MCMC algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712888ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data <- list(\n",
    "  N = nrow(train),\n",
    "  N_test = nrow(test),\n",
    "  K = 2,\n",
    "  y = train$mean_consumption,\n",
    "  l = train %>% select(ratio_house, ratio_apartment)\n",
    ")\n",
    "\n",
    "# Fittage\n",
    "fit1 <- stan(\n",
    "  model_code = mixture,  # Stan program\n",
    "  data = model_data,        # named list of data\n",
    "  chains = 2,               # number of Markov chains. 4 is better, 2 is faster\n",
    "  warmup = 1000,            # number of warmup iterations per chain\n",
    "  iter = 4000,              # total number of iterations per chain\n",
    "  cores = 2,                # number of cores (could use one per chain)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ffe52",
   "metadata": {},
   "source": [
    "Let us now display the results of the fitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5d00b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fit1, pars=c(\"mu\", \"sigma\", \"lp__\"))\n",
    "traceplot(fit1, pars=c(\"mu\", \"sigma\", \"lp__\"))\n",
    "pairs(fit1, pars=c(\"mu\", \"sigma\", \"lp__\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3400bc8",
   "metadata": {},
   "source": [
    "It looks like we can be satisfied with the MCMC convergence: `n_eff` is high enough and `Rhat` close to 1 for all parameters, and all chains seem stationary. The last step is to predict values of the mean consumption of each area in the test data set. We calculate this prediction from the ratios of houses and apartments, and from the mean estimated values of the distributions in the mixture model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5cefe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting distribution parameters from the fit object\n",
    "la <- rstan::extract(fit1, permuted = TRUE)\n",
    "mu <- colMeans(la$mu)\n",
    "sigma <- colMeans(la$sigma)\n",
    "\n",
    "# Predict the consumption of the test data from the ratios\n",
    "test$y <- test$ratio_house * rlnorm(nrow(test), mu[1], sigma[1]) +\n",
    "  test$ratio_apartment * rlnorm(nrow(test), mu[2], sigma[2])\n",
    "\n",
    "# Plot to compare measured and predicted consumption on the test data\n",
    "ggplot(data=test) +\n",
    "  geom_histogram(mapping=aes(x=mean_consumption), bins=50, color='blue', alpha=0.3) +\n",
    "  geom_histogram(mapping=aes(x=y), bins=50, color='red', alpha=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
